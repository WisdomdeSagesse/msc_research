---
title: "Logistic Regression"
author: "Wisdom Fijo"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load data}
data <- readRDS("kiva_loan_data")
head(data)
dim(data)
```

```{r train-test split}
library(tidyverse)
library(stargazer)
data <- data %>%
    select(STATUS, LOAN_AMOUNT, SECTOR, COUNTRY, DISBURSAL_CURRENCY, CURRENCY_EXCHANGE, GENDER, REPAYMENT_INTERVAL, NUM_OWNERS)

set.seed(5)

indexSet <- sample(2, nrow(data), replace = TRUE, prob = c(0.7, 0.3))
train <- data[indexSet == 1, ]
test <- data[indexSet == 2, ]

dim(train)
dim(test)
```



```{r elastic net regression}
set.seed(10)
library(glmnet)
x_train <- model.matrix(STATUS~., train)
y_train <- if_else(train$STATUS == "defaulted", 1, 0)
#fitting the model with various values of alpha to determine the best alpha value
list_of_fits <- list() #this stores the various models
for (i in 0:10){
    fit.name <- paste0("alpha", i/10) #sets up the name for each fit
    #we then append each fit into the list of fits
    list_of_fits[[fit.name]] <- cv.glmnet(x_train, y_train, family = "binomial",
                                       alpha = i/10, type.measure = "class")
}

# to predict best value for alpha
# convert the predictor variables in test data set into a matrix
x_test <- model.matrix(STATUS~., data = test)

results <- data.frame()

for (i in 0:10){
    fit.name <- paste0("alpha", i/10)
    # using each model from the list of fits to predict the test data
    fit_probs <- predict(list_of_fits[[fit.name]], 
                         s = list_of_fits[[fit.name]]$lambda.1se, newx = x_test, 
                     type = "response")
    # convert probabilities to predictions
    fit_preds <- rep("paid", nrow(test))
    fit_preds[fit_probs > 0.5] <- "defaulted"
    
    #calculating the test error rate
    test_error <- mean(fit_preds != test$STATUS)
    #storing the results
    temp <- data.frame(alpha = i/10, error_rate = test_error, fit_name = fit.name)
    results <- rbind(results, temp)
}

stargazer(results,
          title = ("best alpha value - Model 1"),
          type = "text",
          summary = FALSE)

```

```{r training model with best alpha}
# from the results we can determine that at alpha = 0.2 we get the least test error rate

best.fit.model <- cv.glmnet(x_train, y_train, alpha = 0.2, type.measure = "class",
                            family = "binomial")
plot(best.fit.model)

best.fit.probs <- predict(best.fit.model, s= best.fit.model$lambda.1se, 
                                newx = x_test, type = "response")

best.fit.pred <- rep("paid", nrow(test))
best.fit.pred[best.fit.probs > .5] <- "defaulted"

# plotting the confusion matrix
x_tab<- table(Predicted = best.fit.pred, True = test$STATUS)

x_tab

library(caret)
lr1_cfm <- confusionMatrix(x_tab)

# Extracting the important variables

get_coef <- function(best_model){
    coef <- coef(best_model, s= best_model$lambda.1se)
    coef.m <- as.matrix(coef, rownames = T)
    coef_df <- coef.m %>%
    as_tibble(rownames = NA) %>%
    setNames("coefficient")
    colnames(coef_df)
    coef_df
}



lr1_coef_df <- get_coef(best.fit.model)

coef_df_n5 <- lr1_coef_df %>%
    arrange(desc(coefficient)) %>%
    slice(1:5)

coef_df_zero <- lr1_coef_df %>%
    filter(coefficient == 0)


stargazer(coef_df_n5,
          title = ("Top 5 Variables"),
          type = "text",
          summary = FALSE)

stargazer(coef_df_zero,
          title = ("Unimportant Variables"),
          type = "text",
          summary = FALSE)

#Plotting the ROC Curve

lr1_roc <- roc(test$STATUS, best.fit.probs, plot = T, legacy.axes=TRUE, percent=TRUE, 
                  xlab="False Positive Percentage", ylab="True Postive Percentage", 
                  lwd=4)
par(pty = "s")
plot(lr1_roc, main = "ROC Curve Logistic Reg. Model 1", col = "#4daf4a", print.auc=TRUE)


#Getting the performance metrics
#function to generate model performance metrics
modelmetric <- function(CM, ROC){
    accuracy = CM$overall["Accuracy"]
    precision = CM$byClass["Precision"]
    recall = CM$byClass["Recall"]
    specificity = CM$byClass["Specificity"]
    F1 = CM$byClass["F1"]
    AUC = (ROC$auc)/100
    perf_metric = data.frame(Score = c(accuracy, precision, recall, specificity, F1, AUC))
    row.names(perf_metric)[6] <- "AUC"
    perf_metric
}

stargazer(modelmetric(lr1_cfm, lr1_roc),
          title = ("Model 1 Performance - Logistic Regression"),
          type = "text",
          summary = FALSE)

``` 




```{r Plotting the Logistic Regression Model}
library(cowplot)
predicted.data <- data.frame(
    probability.of.default = best.fit.probs[,1],
    Status = test$STATUS
)

predicted.data <- predicted.data[
    order(predicted.data$probability.of.default, decreasing = FALSE),]

predicted.data$rank <- 1:nrow(predicted.data)

ggplot(data = predicted.data, aes(x = rank, y = probability.of.default))+
    geom_point(aes(color = Status), alpha = 1, shape = 4, stroke = 2)+
     theme_bw()+
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank())+
    xlab("Index")+
    ylab("Predicted probability of default")
```

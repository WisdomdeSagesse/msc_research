---
title: "Kenya_Sub-Analysis"
author: "Wisdom"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r Load Data}
loan_df <- readRDS("kiva_loan_data")
```

```{r Subset kenya data}
ky_loan_df <- subset(loan_df, loan_df$COUNTRY == "Kenya")

glimpse(ky_loan_df)

ky_loan_df <- ky_loan_df %>%
    select(LOAN_AMOUNT, SECTOR, DISBURSAL_CURRENCY, CURRENCY_EXCHANGE, GENDER, REPAYMENT_INTERVAL, NUM_OWNERS, STATUS)

ky_loan_df %>%
    select(STATUS) %>%
    summary

# Handling class imbalance

ky_loan_df <- upSample(ky_loan_df[, -8], ky_loan_df$STATUS, yname = "STATUS")


```


```{r Train Test Split}
set.seed(10)

indexSet <- sample(2, nrow(ky_loan_df), replace = TRUE, prob = c(0.7, 0.3))
ky_train <- ky_loan_df[indexSet == 1, ]
ky_test <- ky_loan_df[indexSet == 2, ]

dim(ky_train)
dim(ky_test)
```
```{r Logistic Regression with elastic regularization}

list.of.fits <- list()

ky_xtrain <- model.matrix(STATUS ~ ., ky_train)
ky_ytrain <- if_else(ky_train$STATUS == "defaulted", 1, 0)

for(i in 0:10){
    fit.name <- paste0("alpha", i/10)
    list.of.fits[[fit.name]] <- cv.glmnet(x = ky_xtrain, y = ky_ytrain, 
                                         family = "binomial", alpha = i/10, 
                                         type.measure = "class")
    
}

ky_xtest <- model.matrix(STATUS ~ ., ky_test)
results <- data.frame()

for(i in 0:10){
    fit.name <- paste0("alpha", i/10)
    fit.probs <- predict(list.of.fits[[fit.name]], 
                         s = list.of.fits[[fit.name]]$lambda.1se, newx = ky_xtest,
                         type = "response")
    fit.preds <- rep("paid", nrow(ky_test))
    fit.preds[fit.probs > 0.5] <- "defaulted"
    test_error <- mean(fit.preds != ky_test$STATUS)
    
    temp <- data.frame(alpha = i/10, test_error = test_error, fit_name = fit.name)
    
    results <- rbind(temp, results)
                         
}

results

```

```{r Logistic Regression, alpha = 0.5}

ky.glm.fit <- cv.glmnet(ky_xtrain, ky_ytrain, alpha = 0.5, type.measure = "class",
                        family = "binomial")

ky.probs <- predict(ky.glm.fit, s = ky.glm.fit$lambda.1se, newx = ky_xtest, 
                    type = "response")

ky.preds <- rep("paid", nrow(ky_test))

ky.preds[ky.probs > 0.5] <- "defaulted"

x_tab <- table(Predicted = ky.preds, True = ky_test$STATUS)

x_tab

confusionMatrix(x_tab)

unique(ky_test$STATUS)
```

```{r Decision Tree}

ky.tree <- rpart(STATUS ~ ., data = ky_train, method = "class")

summary(ky.tree)

rpart.plot(ky.tree, extra = 106)
```

```{r Pruning the Tree}

printcp(ky.tree)

plotcp(ky.tree)

cp <- ky.tree$cptable[which.min(ky.tree$cptable[,"xerror"]), "CP"]

ky.ptree <- prune(ky.tree, cp)

ky.ptree.pred <- predict(ky.ptree, ky_test, type = "class")

x_tab <- table(Predicted = ky.ptree.pred, True = ky_test$STATUS)

confusionMatrix(x_tab)

```


```{r Random Forest}

ky.rf <- randomForest(STATUS ~ ., data = ky_train)

ky.rf.pred <- predict(ky.rf, newdata = ky_test, type = "class")

x_tab <- table(Predicted = ky.rf.pred, True = ky_test$STATUS)

confusionMatrix(x_tab)

```


```{r Support Vector Classifier}

library(e1071)
set.seed(5)

ky.svm.class <- tune(svm, STATUS ~ ., data = ky_train, kernel = "linear",
                  ranges = list(cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100)))

summary(ky.svm.class)

bestmod <- ky.svm.class$best.model

summary(bestmod)

ky.class.pred <- predict(bestmod, ky_test)

x_tab <- table(Predicted = ky.class.pred, True = ky_test$STATUS)

confusionMatrix(x_tab)

```

```{r SVM Radial Kernel}

ky.svm <- tune(svm, STATUS ~ ., data = ky_train, kernel = "radial",
                ranges = list(
                    cost = c(0.001, 0.01, 0.1, 1, 5, 10, 100),
                    gamma = c(0.5, 1, 2, 3, 4, 5)
                )
            )

summary(ky.svm)

svm_bestmod <- ky.svm$best.model

ky.svm.pred <- predict(svm_bestmod, ky_test)

x_tab <- table(Predicted = ky.svm.pred, True = ky_test$STATUS)

confusionMatrix(x_tab)


```

